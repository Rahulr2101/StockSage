{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install fastapi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T10:56:44.095411Z","iopub.execute_input":"2025-03-08T10:56:44.095920Z","iopub.status.idle":"2025-03-08T10:56:49.302099Z","shell.execute_reply.started":"2025-03-08T10:56:44.095891Z","shell.execute_reply":"2025-03-08T10:56:49.300967Z"}},"outputs":[{"name":"stdout","text":"Collecting fastapi\n  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\nCollecting starlette<0.47.0,>=0.40.0 (from fastapi)\n  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.11.0a2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.29.0)\nRequirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.2.2)\nDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.46.1-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: starlette, fastapi\nSuccessfully installed fastapi-0.115.11 starlette-0.46.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!huggingface-cli download TheBloke/finance-chat-GGUF finance-chat.Q5_K_M.gguf --local-dir . --local-dir-use-symlinks False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T10:56:49.303583Z","iopub.execute_input":"2025-03-08T10:56:49.303842Z","iopub.status.idle":"2025-03-08T10:57:47.817328Z","shell.execute_reply.started":"2025-03-08T10:56:49.303809Z","shell.execute_reply":"2025-03-08T10:57:47.816377Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n  warnings.warn(\nDownloading 'finance-chat.Q5_K_M.gguf' to '.cache/huggingface/download/bPcXCGMhuMzmlpyLj1x7oLmDoWQ=.a579f4387bede3a82636e13ff0a008f171ebfac41b56d85720817ae667a359f5.incomplete'\nfinance-chat.Q5_K_M.gguf: 100%|████████████| 4.78G/4.78G [00:57<00:00, 83.4MB/s]\nDownload complete. Moving file to finance-chat.Q5_K_M.gguf\nfinance-chat.Q5_K_M.gguf\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install requests\n\nimport requests\nimport json\nimport zlib\n\nYAHOO_TICKERS_URL = \"https://yahoo-finance15.p.rapidapi.com/api/v2/markets/tickers?page=1&type=STOCKS\"\nYAHOO_TICKERS_HEADERS = {\n    \"x-rapidapi-host\": \"yahoo-finance15.p.rapidapi.com\",\n    \"x-rapidapi-key\": \"e5dfb69ac4msh7dcab92ff8a5633p1e73d2jsncf8f43e4a966\",\n    \"Accept\": \"application/json\",\n    \"Accept-Encoding\": \"identity\"\n}\nESG_API_URL_TEMPLATE = \"https://yahoo-finance127.p.rapidapi.com/esg-scores/{symbol}\"\nESG_API_HEADERS = {\n    \"x-rapidapi-host\": \"yahoo-finance127.p.rapidapi.com\",\n    \"x-rapidapi-key\": \"e5dfb69ac4msh7dcab92ff8a5633p1e73d2jsncf8f43e4a966\",\n    \"Accept\": \"application/json\",\n    \"Accept-Encoding\": \"identity\"\n}\n\ndef test_ticker_api():\n    print(\"Testing Yahoo Finance Ticker API...\")\n    try:\n        headers = YAHOO_TICKERS_HEADERS.copy()\n        headers[\"User-Agent\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n        \n        response = requests.get(YAHOO_TICKERS_URL, headers=headers, timeout=10)\n        print(f\"Ticker API Status Code: {response.status_code}\")\n        print(\"Ticker API Response Headers:\")\n        print(response.headers)\n        try:\n            data = response.json()\n            print(\"Ticker API JSON Response:\")\n            print(json.dumps(data, indent=2))\n        except json.JSONDecodeError as e:\n            print(\"JSON decode error:\", e)\n            print(\"Response content (first 200 characters):\")\n            print(response.content[:200])\n    except Exception as e:\n        print(\"Exception during ticker API test:\", str(e))\n\ndef test_esg_api(symbol=\"AAPL\"):\n    print(f\"\\nTesting ESG API for symbol: {symbol}...\")\n    try:\n        url = ESG_API_URL_TEMPLATE.format(symbol=symbol)\n        headers = ESG_API_HEADERS.copy()\n        headers[\"User-Agent\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n        \n        response = requests.get(url, headers=headers, timeout=10)\n        print(f\"ESG API Status Code for {symbol}: {response.status_code}\")\n        print(\"ESG API Response Headers:\")\n        print(response.headers)\n        try:\n            data = response.json()\n            print(f\"ESG API JSON Response for {symbol}:\")\n            print(json.dumps(data, indent=2))\n        except json.JSONDecodeError as e:\n            print(\"JSON decode error for ESG API:\", e)\n            print(\"Response content (first 200 characters):\")\n            print(response.content[:200])\n    except Exception as e:\n        print(f\"Exception during ESG API test for {symbol}:\", str(e))\n\ntest_ticker_api()\ntest_esg_api(\"AAPL\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T10:57:47.818834Z","iopub.execute_input":"2025-03-08T10:57:47.819152Z","iopub.status.idle":"2025-03-08T10:57:52.889051Z","shell.execute_reply.started":"2025-03-08T10:57:47.819127Z","shell.execute_reply":"2025-03-08T10:57:52.887927Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2025.1.31)\nTesting Yahoo Finance Ticker API...\nTicker API Status Code: 200\nTicker API Response Headers:\n{'Date': 'Sat, 08 Mar 2025 10:57:52 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'expires': '-1', 'Cache-Control': 'private, must-revalidate', 'NEL': '{\"success_fraction\":0,\"report_to\":\"cf-nel\",\"max_age\":604800}', 'x-xss-protection': '1; mode=block', 'vary': 'Origin, accept-encoding', 'alt-svc': 'h3=\":443\"; ma=86400', 'x-content-type-options': 'nosniff', 'CF-RAY': '91d1d06c7fc739a4-IAD', 'cf-cache-status': 'DYNAMIC', 'server-timing': 'cfL4;desc=\"?proto=TCP&rtt=2361&min_rtt=1766&rtt_var=1022&sent=5&recv=6&lost=0&retrans=0&sent_bytes=2995&recv_bytes=1277&delivery_rate=1653454&cwnd=252&unsent_bytes=0&cid=d87330b9857433c1&ts=369&x=0\"', 'x-frame-options': 'SAMEORIGIN', 'Report-To': '{\"endpoints\":[{\"url\":\"https:\\\\/\\\\/a.nel.cloudflare.com\\\\/report\\\\/v4?s=KmPH22STAjfgvvIfyJTpk8R1I2R4%2BaBbELvDC2qHqwvlR9K%2BX1sItDhnyB4TZr9CL7nVgYVKht3YMHGXOrtTF2gH0RrX2qcWXsp2FEMVpFaRGCnjxwxiCmVioaZu%2Bky06DPxICDPFcM%3D\"}],\"group\":\"cf-nel\",\"max_age\":604800}', 'pragma': 'no-cache', 'X-RateLimit-Requests-Limit': '500', 'X-RateLimit-Requests-Remaining': '449', 'X-RateLimit-Requests-Reset': '2670787', 'X-RateLimit-Old-Requests-Limit': '500', 'X-RateLimit-Old-Requests-Remaining': '449', 'X-RateLimit-Old-Requests-Reset': '2670787', 'X-RateLimit-rapid-free-plans-hard-limit-Limit': '500000', 'X-RateLimit-rapid-free-plans-hard-limit-Remaining': '499951', 'X-RateLimit-rapid-free-plans-hard-limit-Reset': '2670787', 'Server': 'RapidAPI-1.2.8', 'X-RapidAPI-Version': '1.2.8', 'X-RapidAPI-Region': 'AWS - us-east-1', 'X-RapidAPI-Request-Id': 'c22662f77a7a4d97999759578870f05000470559677d9c469279e06d3519e2cf'}\nTicker API JSON Response:\n{\n  \"meta\": {\n    \"version\": \"v1.0\",\n    \"status\": 200,\n    \"copywrite\": \"https://apicalls.io\",\n    \"totalrecords\": 6953,\n    \"headers\": {\n      \"symbol\": \"Symbol\",\n      \"name\": \"Name\",\n      \"lastsale\": \"Last Sale\",\n      \"netchange\": \"Net Change\",\n      \"pctchange\": \"% Change\",\n      \"marketCap\": \"Market Cap\"\n    }\n  },\n  \"body\": [\n    {\n      \"symbol\": \"ABBV\",\n      \"name\": \"AbbVie Inc. Common Stock\",\n      \"lastsale\": \"$214.29\",\n      \"netchange\": \"3.54\",\n      \"pctchange\": \"1.68%\",\n      \"marketCap\": \"378,297,892,735\"\n    },\n    {\n      \"symbol\": \"HD\",\n      \"name\": \"Home Depot, Inc. (The) Common Stock\",\n      \"lastsale\": \"$376.80\",\n      \"netchange\": \"-4.93\",\n      \"pctchange\": \"-1.291%\",\n      \"marketCap\": \"374,299,032,202\"\n    },\n    {\n      \"symbol\": \"FMX\",\n      \"name\": \"Fomento Economico Mexicano S.A.B. de C.V. Common Stock\",\n      \"lastsale\": \"$97.72\",\n      \"netchange\": \"0.29\",\n      \"pctchange\": \"0.298%\",\n      \"marketCap\": \"370,742,313,573\"\n    },\n    {\n      \"symbol\": \"SAP\",\n      \"name\": \"SAP  SE ADS\",\n      \"lastsale\": \"$276.80\",\n      \"netchange\": \"-2.54\",\n      \"pctchange\": \"-0.909%\",\n      \"marketCap\": \"340,049,971,418\"\n    },\n    {\n      \"symbol\": \"BABA\",\n      \"name\": \"Alibaba Group Holding Limited American Depositary Shares each representing eight Ordinary share\",\n      \"lastsale\": \"$140.62\",\n      \"netchange\": \"0.67\",\n      \"pctchange\": \"0.479%\",\n      \"marketCap\": \"334,931,041,292\"\n    },\n    {\n      \"symbol\": \"BAC\",\n      \"name\": \"Bank of America Corporation Common Stock\",\n      \"lastsale\": \"$41.40\",\n      \"netchange\": \"-0.06\",\n      \"pctchange\": \"-0.145%\",\n      \"marketCap\": \"314,833,639,144\"\n    },\n    {\n      \"symbol\": \"KO\",\n      \"name\": \"Coca-Cola Company (The) Common Stock\",\n      \"lastsale\": \"$71.43\",\n      \"netchange\": \"0.97\",\n      \"pctchange\": \"1.377%\",\n      \"marketCap\": \"307,220,458,215\"\n    },\n    {\n      \"symbol\": \"TMUS\",\n      \"name\": \"T-Mobile US, Inc. Common Stock\",\n      \"lastsale\": \"$265.24\",\n      \"netchange\": \"2.29\",\n      \"pctchange\": \"0.871%\",\n      \"marketCap\": \"302,836,431,068\"\n    },\n    {\n      \"symbol\": \"SMFG\",\n      \"name\": \"Sumitomo Mitsui Financial Group Inc Unsponsored American Depositary Shares (Japan)\",\n      \"lastsale\": \"$15.38\",\n      \"netchange\": \"0.01\",\n      \"pctchange\": \"0.065%\",\n      \"marketCap\": \"301,840,573,823\"\n    },\n    {\n      \"symbol\": \"ASML\",\n      \"name\": \"ASML Holding N.V. New York Registry Shares\",\n      \"lastsale\": \"$732.22\",\n      \"netchange\": \"17.38\",\n      \"pctchange\": \"2.431%\",\n      \"marketCap\": \"287,970,205,458\"\n    },\n    {\n      \"symbol\": \"CVX\",\n      \"name\": \"Chevron Corporation Common Stock\",\n      \"lastsale\": \"$156.34\",\n      \"netchange\": \"3.39\",\n      \"pctchange\": \"2.216%\",\n      \"marketCap\": \"275,251,975,275\"\n    },\n    {\n      \"symbol\": \"CRM\",\n      \"name\": \"Salesforce, Inc. Common Stock\",\n      \"lastsale\": \"$282.89\",\n      \"netchange\": \"-3.16\",\n      \"pctchange\": \"-1.105%\",\n      \"marketCap\": \"271,857,290,000\"\n    },\n    {\n      \"symbol\": \"TM\",\n      \"name\": \"Toyota Motor Corporation Common Stock\",\n      \"lastsale\": \"$190.18\",\n      \"netchange\": \"2.67\",\n      \"pctchange\": \"1.424%\",\n      \"marketCap\": \"256,251,803,667\"\n    },\n    {\n      \"symbol\": \"CSCO\",\n      \"name\": \"Cisco Systems, Inc. Common Stock (DE)\",\n      \"lastsale\": \"$63.94\",\n      \"netchange\": \"0.53\",\n      \"pctchange\": \"0.836%\",\n      \"marketCap\": \"254,372,018,102\"\n    },\n    {\n      \"symbol\": \"IBM\",\n      \"name\": \"International Business Machines Corporation Common Stock\",\n      \"lastsale\": \"$261.54\",\n      \"netchange\": \"12.85\",\n      \"pctchange\": \"5.167%\",\n      \"marketCap\": \"242,516,713,391\"\n    },\n    {\n      \"symbol\": \"AZN\",\n      \"name\": \"AstraZeneca PLC American Depositary Shares\",\n      \"lastsale\": \"$77.50\",\n      \"netchange\": \"0.03\",\n      \"pctchange\": \"0.039%\",\n      \"marketCap\": \"240,340,075,770\"\n    },\n    {\n      \"symbol\": \"MRK\",\n      \"name\": \"Merck & Company, Inc. Common Stock (new)\",\n      \"lastsale\": \"$94.65\",\n      \"netchange\": \"0.65\",\n      \"pctchange\": \"0.691%\",\n      \"marketCap\": \"239,089,330,116\"\n    },\n    {\n      \"symbol\": \"ABT\",\n      \"name\": \"Abbott Laboratories Common Stock\",\n      \"lastsale\": \"$137.14\",\n      \"netchange\": \"2.06\",\n      \"pctchange\": \"1.525%\",\n      \"marketCap\": \"237,845,112,585\"\n    },\n    {\n      \"symbol\": \"PM\",\n      \"name\": \"Philip Morris International Inc Common Stock\",\n      \"lastsale\": \"$150.95\",\n      \"netchange\": \"-2.60\",\n      \"pctchange\": \"-1.693%\",\n      \"marketCap\": \"234,705,697,510\"\n    },\n    {\n      \"symbol\": \"WFC\",\n      \"name\": \"Wells Fargo & Company Common Stock\",\n      \"lastsale\": \"$71.05\",\n      \"netchange\": \"-1.60\",\n      \"pctchange\": \"-2.202%\",\n      \"marketCap\": \"233,625,656,651\"\n    },\n    {\n      \"symbol\": \"MCD\",\n      \"name\": \"McDonald's Corporation Common Stock\",\n      \"lastsale\": \"$321.29\",\n      \"netchange\": \"10.92\",\n      \"pctchange\": \"3.518%\",\n      \"marketCap\": \"229,549,219,349\"\n    },\n    {\n      \"symbol\": \"NVS\",\n      \"name\": \"Novartis AG Common Stock\",\n      \"lastsale\": \"$115.57\",\n      \"netchange\": \"2.70\",\n      \"pctchange\": \"2.392%\",\n      \"marketCap\": \"228,261,064,391\"\n    },\n    {\n      \"symbol\": \"LIN\",\n      \"name\": \"Linde plc Ordinary Shares\",\n      \"lastsale\": \"$468.77\",\n      \"netchange\": \"2.61\",\n      \"pctchange\": \"0.56%\",\n      \"marketCap\": \"221,686,779,170\"\n    },\n    {\n      \"symbol\": \"ACN\",\n      \"name\": \"Accenture plc Class A Ordinary Shares (Ireland)\",\n      \"lastsale\": \"$342.18\",\n      \"netchange\": \"0.34\",\n      \"pctchange\": \"0.099%\",\n      \"marketCap\": \"214,132,032,106\"\n    },\n    {\n      \"symbol\": \"PEP\",\n      \"name\": \"PepsiCo, Inc. Common Stock\",\n      \"lastsale\": \"$154.44\",\n      \"netchange\": \"1.185\",\n      \"pctchange\": \"0.773%\",\n      \"marketCap\": \"211,814,434,981\"\n    }\n  ]\n}\n\nTesting ESG API for symbol: AAPL...\nESG API Status Code for AAPL: 200\nESG API Response Headers:\n{'Date': 'Sat, 08 Mar 2025 10:57:52 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '1133', 'Connection': 'keep-alive', 'Cache-Control': 'public, max-age=0, must-revalidate', 'Etag': 'W/\"46d-LhZ4TxfatNwxsJXay7dWh/261Ko\"', 'X-Powered-By': 'Express', 'X-Vercel-Id': 'iad1::fra1::j44tc-1741431472674-685db6b99902', 'X-Vercel-Cache': 'MISS', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload', 'Age': '0', 'X-RateLimit-Requests-Limit': '150', 'X-RateLimit-Requests-Remaining': '134', 'X-RateLimit-Requests-Reset': '2662834', 'X-RateLimit-rapid-free-plans-hard-limit-Limit': '500000', 'X-RateLimit-rapid-free-plans-hard-limit-Remaining': '499984', 'X-RateLimit-rapid-free-plans-hard-limit-Reset': '2662834', 'Server': 'RapidAPI-1.2.8', 'X-RapidAPI-Version': '1.2.8', 'X-RapidAPI-Region': 'AWS - us-east-1', 'X-RapidAPI-Request-Id': '2fedec4554bddc2cd7c04838b968597017f9c2e0e7680ffe0abba77e90373b6c'}\nESG API JSON Response for AAPL:\n{\n  \"maxAge\": 86400,\n  \"totalEsg\": {\n    \"raw\": 16.36,\n    \"fmt\": \"16.4\"\n  },\n  \"environmentScore\": {\n    \"raw\": 0.55,\n    \"fmt\": \"0.6\"\n  },\n  \"socialScore\": {\n    \"raw\": 7.31,\n    \"fmt\": \"7.3\"\n  },\n  \"governanceScore\": {\n    \"raw\": 8.5,\n    \"fmt\": \"8.5\"\n  },\n  \"ratingYear\": 2025,\n  \"ratingMonth\": 2,\n  \"highestControversy\": 3,\n  \"peerCount\": 236,\n  \"esgPerformance\": \"LAG_PERF\",\n  \"peerGroup\": \"Technology Hardware\",\n  \"relatedControversy\": [\n    \"Customer Incidents;Business Ethics Incidents\"\n  ],\n  \"peerEsgScorePerformance\": {\n    \"min\": 4.46,\n    \"avg\": 16.28644067796609,\n    \"max\": 29.96\n  },\n  \"peerGovernancePerformance\": {\n    \"min\": 0.76,\n    \"avg\": 4.933218390804596,\n    \"max\": 9.93\n  },\n  \"peerSocialPerformance\": {\n    \"min\": 1.4,\n    \"avg\": 5.23896551724138,\n    \"max\": 12.56\n  },\n  \"peerEnvironmentPerformance\": {\n    \"min\": 0.17,\n    \"avg\": 3.5152873563218376,\n    \"max\": 11.83\n  },\n  \"peerHighestControversyPerformance\": {\n    \"min\": 0,\n    \"avg\": 0.5550847457627118,\n    \"max\": 3\n  },\n  \"percentile\": null,\n  \"environmentPercentile\": null,\n  \"socialPercentile\": null,\n  \"governancePercentile\": null,\n  \"adult\": false,\n  \"alcoholic\": false,\n  \"animalTesting\": false,\n  \"catholic\": null,\n  \"controversialWeapons\": false,\n  \"smallArms\": false,\n  \"furLeather\": false,\n  \"gambling\": false,\n  \"gmo\": false,\n  \"militaryContract\": false,\n  \"nuclear\": false,\n  \"pesticides\": false,\n  \"palmOil\": false,\n  \"coal\": false,\n  \"tobacco\": false\n}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install llama-cpp-python\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T10:58:56.425080Z","iopub.execute_input":"2025-03-08T10:58:56.425363Z","iopub.status.idle":"2025-03-08T11:00:23.124430Z","shell.execute_reply.started":"2025-03-08T10:58:56.425339Z","shell.execute_reply":"2025-03-08T11:00:23.123603Z"}},"outputs":[{"name":"stdout","text":"Collecting llama-cpp-python\n  Using cached llama_cpp_python-0.3.7.tar.gz (66.7 MB)\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\nRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.26.4)\nCollecting diskcache>=5.6.1 (from llama-cpp-python)\n  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->llama-cpp-python) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20.0->llama-cpp-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20.0->llama-cpp-python) (2024.2.0)\nUsing cached diskcache-5.6.3-py3-none-any.whl (45 kB)\nBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.7-cp310-cp310-linux_x86_64.whl size=4601123 sha256=5ef59c9115a9a80f9493dd331e9369db3a87b3a35a60061f01b9f3c077d9fcce\n  Stored in directory: /root/.cache/pip/wheels/5c/8f/58/a39eb13258f3bbf64bb36ed76d31979579a6f175be38de06b7\nSuccessfully built llama-cpp-python\nInstalling collected packages: diskcache, llama-cpp-python\nSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.3.7\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nimport requests\nfrom llama_cpp import Llama\nimport logging\nimport time\nimport json\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(\"finance_api.log\"),\n        logging.StreamHandler()\n    ]\n)\nlogger = logging.getLogger(__name__)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:00:23.125576Z","iopub.execute_input":"2025-03-08T11:00:23.125808Z","iopub.status.idle":"2025-03-08T11:00:23.252233Z","shell.execute_reply.started":"2025-03-08T11:00:23.125787Z","shell.execute_reply":"2025-03-08T11:00:23.251383Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\nYAHOO_TICKERS_URL = \"https://yahoo-finance15.p.rapidapi.com/api/v2/markets/tickers\"\nYAHOO_TICKERS_HEADERS = {\n    \"x-rapidapi-host\": \"yahoo-finance15.p.rapidapi.com\",\n    \"x-rapidapi-key\": \"e5dfb69ac4msh7dcab92ff8a5633p1e73d2jsncf8f43e4a966\",\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n\nESG_API_URL_TEMPLATE = \"https://yahoo-finance127.p.rapidapi.com/esg-scores/{symbol}\"\nESG_API_HEADERS = {\n    \"x-rapidapi-host\": \"yahoo-finance127.p.rapidapi.com\",\n    \"x-rapidapi-key\": \"e5dfb69ac4msh7dcab92ff8a5633p1e73d2jsncf8f43e4a966\",\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:00:28.307688Z","iopub.execute_input":"2025-03-08T11:00:28.308073Z","iopub.status.idle":"2025-03-08T11:00:28.312410Z","shell.execute_reply.started":"2025-03-08T11:00:28.308050Z","shell.execute_reply":"2025-03-08T11:00:28.311641Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def get_all_ticker_pages(max_pages=20, symbol_to_find=None):\n\n    all_tickers = []\n    found_symbol = False\n    \n    for page in range(1, max_pages + 1):\n        logger.info(f\"Fetching ticker page {page}/{max_pages}\")\n        \n        try:\n            params = {\n                \"page\": page,\n                \"type\": \"STOCKS\"\n            }\n            \n            # Add backoff retry logic\n            max_retries = 3\n            retry_delay = 2  # seconds\n            \n            for attempt in range(max_retries):\n                try:\n                    response = requests.get(\n                        YAHOO_TICKERS_URL, \n                        headers=YAHOO_TICKERS_HEADERS, \n                        params=params,\n                        timeout=10\n                    )\n                    \n                    # Log response details\n                    logger.info(f\"Page {page} status code: {response.status_code}\")\n                    logger.info(f\"Page {page} headers: {dict(response.headers)}\")\n                    \n                    if response.status_code == 200:\n                        data = response.json()\n                        logger.info(f\"Page {page} response structure: {list(data.keys())}\")\n                        \n                        # Check if body is in the response\n                        if \"body\" in data and isinstance(data[\"body\"], list):\n                            page_tickers = data[\"body\"]\n                            logger.info(f\"Found {len(page_tickers)} tickers in page {page}\")\n                            \n                            # Add tickers from this page to our collection\n                            all_tickers.extend(page_tickers)\n                            \n                            # If looking for a specific symbol, check if it's in this page\n                            if symbol_to_find:\n                                for ticker in page_tickers:\n                                    if ticker.get(\"symbol\") == symbol_to_find:\n                                        logger.info(f\"Found target symbol {symbol_to_find} on page {page}\")\n                                        found_symbol = True\n                                        break\n                        else:\n                            logger.warning(f\"No 'body' list found in page {page} response\")\n                            # Log the actual response structure for debugging\n                            logger.warning(f\"Response content: {response.text[:500]}...\")\n                        \n                        # Success, break the retry loop\n                        break\n                    \n                    elif response.status_code == 429:  # Rate limit exceeded\n                        retry_after = int(response.headers.get('Retry-After', retry_delay * (attempt + 1)))\n                        logger.warning(f\"Rate limit hit on attempt {attempt+1}, waiting {retry_after} seconds\")\n                        time.sleep(retry_after)\n                    \n                    else:\n                        logger.error(f\"Error fetching page {page}: Status {response.status_code}\")\n                        logger.error(f\"Response: {response.text[:500]}...\")\n                        break  # Non-retryable error\n                \n                except requests.exceptions.RequestException as e:\n                    logger.error(f\"Request exception on page {page}, attempt {attempt+1}: {str(e)}\")\n                    if attempt < max_retries - 1:\n                        time.sleep(retry_delay * (attempt + 1))\n                    else:\n                        logger.error(f\"Max retries reached for page {page}\")\n            \n            # If we found our target symbol or hit an error, stop fetching pages\n            if found_symbol:\n                break\n                \n        except Exception as e:\n            logger.exception(f\"Unexpected error fetching page {page}: {str(e)}\")\n    \n    logger.info(f\"Total tickers collected: {len(all_tickers)}\")\n    return all_tickers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:21:45.744164Z","iopub.execute_input":"2025-03-08T11:21:45.744449Z","iopub.status.idle":"2025-03-08T11:21:45.752939Z","shell.execute_reply.started":"2025-03-08T11:21:45.744424Z","shell.execute_reply":"2025-03-08T11:21:45.752159Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def search_ticker_by_symbol(symbol, tickers=None, max_pages=3):\n\n    logger.info(f\"Searching for ticker symbol: {symbol}\")\n    \n    # Use provided tickers if available, otherwise fetch them\n    if tickers is None:\n        tickers = get_all_ticker_pages(max_pages=max_pages, symbol_to_find=symbol)\n    \n    # Search for the symbol in our ticker data\n    for ticker in tickers:\n        if ticker.get(\"symbol\") == symbol:\n            logger.info(f\"Found ticker data for {symbol}\")\n            logger.debug(f\"Ticker data: {ticker}\")\n            return ticker\n    \n    logger.warning(f\"Ticker {symbol} not found in {len(tickers)} results\")\n    return None\n\ndef get_esg_data(symbol):\n    \"\"\"Fetch ESG score data for a given symbol from Yahoo Finance ESG API.\"\"\"\n    logger.info(f\"Fetching ESG data for symbol: {symbol}\")\n    \n    try:\n        url = ESG_API_URL_TEMPLATE.format(symbol=symbol)\n        \n        # Add retry logic\n        max_retries = 3\n        retry_delay = 2  # seconds\n        \n        for attempt in range(max_retries):\n            try:\n                response = requests.get(\n                    url, \n                    headers=ESG_API_HEADERS,\n                    timeout=10\n                )\n                \n                logger.info(f\"ESG API status code for {symbol}: {response.status_code}\")\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    logger.info(f\"ESG data keys for {symbol}: {list(data.keys())}\")\n                    return data\n                \n                elif response.status_code == 429:  # Rate limit exceeded\n                    retry_after = int(response.headers.get('Retry-After', retry_delay * (attempt + 1)))\n                    logger.warning(f\"Rate limit hit on ESG for {symbol}, waiting {retry_after} seconds\")\n                    time.sleep(retry_after)\n                \n                else:\n                    logger.error(f\"ESG API error for {symbol}: Status {response.status_code}\")\n                    logger.error(f\"Response: {response.text[:500]}...\")\n                    return {}\n                    \n            except requests.exceptions.RequestException as e:\n                logger.error(f\"Request exception on ESG for {symbol}, attempt {attempt+1}: {str(e)}\")\n                if attempt < max_retries - 1:\n                    time.sleep(retry_delay * (attempt + 1))\n                else:\n                    logger.error(f\"Max retries reached for ESG data on {symbol}\")\n                    return {}\n        \n    except Exception as e:\n        logger.exception(f\"Unexpected error fetching ESG data for {symbol}: {str(e)}\")\n        return {}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:00:33.099630Z","iopub.execute_input":"2025-03-08T11:00:33.099944Z","iopub.status.idle":"2025-03-08T11:00:33.107503Z","shell.execute_reply.started":"2025-03-08T11:00:33.099921Z","shell.execute_reply":"2025-03-08T11:00:33.106789Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def check_model_file(model_path):\n    \"\"\"Check if the model file exists and log its status.\"\"\"\n    import os\n    if os.path.exists(model_path):\n        model_size = os.path.getsize(model_path) / (1024 * 1024)  # Size in MB\n        logger.info(f\"Model file found at {model_path} ({model_size:.2f} MB)\")\n        return True\n    else:\n        logger.error(f\"Model file not found at {model_path}\")\n        return False\n\ndef initialize_llama(model_path):\n    \"\"\"Initialize the Llama model with GPU support and fallback to CPU.\"\"\"\n    logger.info(\"Initializing Llama model with GPU support...\")\n    \n    if not check_model_file(model_path):\n        logger.error(\"Cannot initialize model: file not found\")\n        return None\n    \n    try:\n        # First try to initialize with GPU support\n        model = Llama(\n            model_path=model_path,\n            n_ctx=4096,\n            n_threads=4,\n            n_gpu_layers=-1  # Use all layers on GPU\n        )\n        logger.info(\"Llama model initialized successfully with GPU support\")\n        return model\n    except Exception as e:\n        logger.exception(f\"Error initializing Llama model with GPU: {str(e)}\")\n        logger.info(\"Falling back to CPU initialization...\")\n        try:\n            # Fallback to CPU\n            model = Llama(\n                model_path=model_path,\n                n_ctx=4096,\n                n_threads=4\n            )\n            logger.info(\"Llama model initialized successfully on CPU\")\n            return model\n        except Exception as e2:\n            logger.exception(f\"Error initializing Llama model on CPU: {str(e2)}\")\n            return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:00:35.494826Z","iopub.execute_input":"2025-03-08T11:00:35.495123Z","iopub.status.idle":"2025-03-08T11:00:35.501107Z","shell.execute_reply.started":"2025-03-08T11:00:35.495097Z","shell.execute_reply":"2025-03-08T11:00:35.500181Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\n\ndef chat_response(user_message, model_path=\"/kaggle/working/finance-chat.Q5_K_M.gguf\"):\n    \"\"\"\n    Generate a response to a user's financial query with detailed logging.\n    \n    Args:\n        user_message: The user's query\n        model_path: Path to the GGUF model file\n        \n    Returns:\n        Generated response string\n    \"\"\"\n    logger.info(f\"Processing user query: {user_message}\")\n    \n    # Check if query is specifically looking for a symbol\n    import re\n    symbol_match = re.search(r'\\b([A-Z]{1,5})\\b', user_message)\n    target_symbol = None\n    \n    if symbol_match:\n        potential_symbol = symbol_match.group(1)\n        if len(potential_symbol) >= 2:  # Most stock symbols are at least 2 characters\n            target_symbol = potential_symbol\n            logger.info(f\"Detected potential stock symbol in query: {target_symbol}\")\n    \n    # Fetch all ticker data or search for specific symbol\n    if target_symbol:\n        # First, try to directly get the specific ticker\n        ticker_data = search_ticker_by_symbol(target_symbol, max_pages=20)\n        if ticker_data:\n            tickers = [ticker_data]\n        else:\n            # If not found, get general top tickers\n            tickers = get_all_ticker_pages(max_pages=2)[:3]\n    else:\n        # No specific symbol, get top tickers\n        tickers = get_all_ticker_pages(max_pages=2)[:3]\n    \n    # Prepare ticker summary for prompt\n    ticker_summary = \"\"\n    for ticker in tickers:\n        symbol = ticker.get(\"symbol\", \"N/A\")\n        price = ticker.get(\"lastsale\", \"N/A\")\n        change_pct = ticker.get(\"pctchange\", \"N/A\")\n        \n        # Log ticker details\n        logger.info(f\"Including ticker in summary: {symbol} @ {price} ({change_pct})\")\n        \n        # Only fetch ESG data for the target symbol or for display tickers if no target\n        if symbol == target_symbol or not target_symbol:\n            esg_data = get_esg_data(symbol)\n            if esg_data and \"totalEsg\" in esg_data:\n                esg_score = esg_data[\"totalEsg\"].get(\"fmt\", \"N/A\")\n                env_score = esg_data.get(\"environmentScore\", {}).get(\"fmt\", \"N/A\")\n                social_score = esg_data.get(\"socialScore\", {}).get(\"fmt\", \"N/A\")\n                gov_score = esg_data.get(\"governanceScore\", {}).get(\"fmt\", \"N/A\")\n                \n                esg_text = (f\"ESG Score: {esg_score}, Environmental: {env_score}, \"\n                           f\"Social: {social_score}, Governance: {gov_score}\")\n                logger.info(f\"ESG data for {symbol}: {esg_text}\")\n            else:\n                esg_text = \"No ESG data available\"\n                logger.warning(f\"No ESG data found for {symbol}\")\n        else:\n            esg_text = \"ESG data not fetched\"\n        \n        ticker_summary += f\"{symbol}: Price {price} ({change_pct}); {esg_text}. \"\n    \n    if not ticker_summary:\n        ticker_summary = \"No ticker information available.\"\n        logger.warning(\"No ticker data could be retrieved\")\n    \n    # Log the final ticker summary\n    logger.info(f\"Final ticker summary: {ticker_summary}\")\n    \n    # Initialize the model with GPU support\n    llama = initialize_llama(model_path)\n    if not llama:\n        return \"I'm sorry, but I'm unable to process your request at the moment due to a technical issue with the language model.\"\n    \n    # Construct the enriched prompt\n    enriched_prompt = (\n        \"Answer the following financial query by providing a detailed analysis, \"\n        \"recommendations for greener and sustainable alternatives, and insights on sustainable finance. \"\n        \"Focus on clear, actionable financial Q&A while incorporating the data provided below.\\n\\n\"\n        f\"User Query: {user_message}\\n\\n\"\n        f\"Ticker and ESG Information: {ticker_summary}\\n\\n\"\n        \"Answer:\"\n    )\n    \n    logger.info(\"Sending prompt to Llama model\")\n    logger.debug(f\"Full prompt: {enriched_prompt}\")\n    \n    try:\n\n        output = llama(\n            prompt=enriched_prompt,\n            max_tokens=800,\n            temperature=0.7,\n            top_p=0.95,\n        )\n        \n        if isinstance(output, dict):\n            logger.info(\"Llama returned dictionary output\")\n            reply = output.get(\"choices\", [{}])[0].get(\"text\", \"\")\n        elif isinstance(output, str):\n            logger.info(\"Llama returned string output\")\n            reply = output\n        else:\n            logger.warning(f\"Unexpected output type from Llama: {type(output)}\")\n            if hasattr(output, \"__getitem__\"):\n                try:\n                    first_item = output[0]\n                    if isinstance(first_item, dict) and \"text\" in first_item:\n                        reply = first_item[\"text\"]\n                    else:\n                        reply = str(first_item)\n                except (IndexError, TypeError):\n                    reply = str(output)\n            else:\n                reply = str(output)\n        \n        logger.info(\"Successfully generated response\")\n        logger.debug(f\"Model response: {reply}\")\n        \n        return reply.strip()\n        \n    except Exception as e:\n        logger.exception(f\"Error generating response with Llama: {str(e)}\")\n        return \"I apologize, but I encountered an error while processing your request. Please try again with a different query.\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:00:37.365986Z","iopub.execute_input":"2025-03-08T11:00:37.366277Z","iopub.status.idle":"2025-03-08T11:00:37.378339Z","shell.execute_reply.started":"2025-03-08T11:00:37.366252Z","shell.execute_reply":"2025-03-08T11:00:37.377414Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Add CUDA installation code if needed\ndef install_cuda_support():\n    \"\"\"Install CUDA-enabled version of llama-cpp-python.\"\"\"\n    try:\n        logger.info(\"Installing CUDA-enabled llama-cpp-python...\")\n        import sys\n        import subprocess\n        \n        # Uninstall current version\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"llama-cpp-python\"])\n        \n        # Install with CUDA support\n        env = {\"CMAKE_ARGS\": \"-DLLAMA_CUBLAS=on\", \"FORCE_CMAKE\": \"1\"}\n        subprocess.check_call(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"llama-cpp-python\"],\n            env=env\n        )\n        \n        logger.info(\"Successfully installed CUDA-enabled llama-cpp-python\")\n        return True\n    except Exception as e:\n        logger.exception(f\"Failed to install CUDA support: {str(e)}\")\n        return False\n\nif __name__ == \"__main__\":\n    \n    user_query = \"give me some sustainable finance strategies and some sustainable stocks\"\n    \n    logger.info(\"Starting test run with query: \" + user_query)\n    \n    try:\n        reply = chat_response(user_query)\n        print(\"\\nChatbot Response:\\n\" + \"-\"*50)\n        print(reply)\n        print(\"-\"*50)\n        \n        logger.info(\"Test completed successfully\")\n        \n    except Exception as e:\n        logger.exception(f\"Test failed with exception: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T11:22:34.794792Z","iopub.execute_input":"2025-03-08T11:22:34.795097Z","iopub.status.idle":"2025-03-08T11:26:10.954764Z","shell.execute_reply.started":"2025-03-08T11:22:34.795074Z","shell.execute_reply":"2025-03-08T11:26:10.953867Z"}},"outputs":[{"name":"stderr","text":"llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /kaggle/working/finance-chat.Q5_K_M.gguf (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = LLaMA v2\nllama_model_loader: - kv   2:                       llama.context_length u32              = 4096\nllama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   4:                          llama.block_count u32              = 32\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\nllama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                          general.file_type u32              = 17\nllama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\nllama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32001]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\nllama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32001]   = [0.000000, 0.000000, 0.000000, 0.0000...\nllama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32001]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\nllama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\nllama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\nllama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\nllama_model_loader: - kv  18:            tokenizer.ggml.padding_token_id u32              = 32000\nllama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\nllama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\nllama_model_loader: - kv  21:               general.quantization_version u32              = 2\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q5_K:  193 tensors\nllama_model_loader: - type q6_K:   33 tensors\nprint_info: file format = GGUF V3 (latest)\nprint_info: file type   = Q5_K - Medium\nprint_info: file size   = 4.45 GiB (5.68 BPW) \ninit_tokenizer: initializing tokenizer for type 1\nload: control token:      2 '</s>' is not marked as EOG\nload: control token:      1 '<s>' is not marked as EOG\nload: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\nload: special tokens cache size = 3\nload: token to piece cache size = 0.1684 MB\nprint_info: arch             = llama\nprint_info: vocab_only       = 0\nprint_info: n_ctx_train      = 4096\nprint_info: n_embd           = 4096\nprint_info: n_layer          = 32\nprint_info: n_head           = 32\nprint_info: n_head_kv        = 32\nprint_info: n_rot            = 128\nprint_info: n_swa            = 0\nprint_info: n_embd_head_k    = 128\nprint_info: n_embd_head_v    = 128\nprint_info: n_gqa            = 1\nprint_info: n_embd_k_gqa     = 4096\nprint_info: n_embd_v_gqa     = 4096\nprint_info: f_norm_eps       = 0.0e+00\nprint_info: f_norm_rms_eps   = 1.0e-05\nprint_info: f_clamp_kqv      = 0.0e+00\nprint_info: f_max_alibi_bias = 0.0e+00\nprint_info: f_logit_scale    = 0.0e+00\nprint_info: n_ff             = 11008\nprint_info: n_expert         = 0\nprint_info: n_expert_used    = 0\nprint_info: causal attn      = 1\nprint_info: pooling type     = 0\nprint_info: rope type        = 0\nprint_info: rope scaling     = linear\nprint_info: freq_base_train  = 10000.0\nprint_info: freq_scale_train = 1\nprint_info: n_ctx_orig_yarn  = 4096\nprint_info: rope_finetuned   = unknown\nprint_info: ssm_d_conv       = 0\nprint_info: ssm_d_inner      = 0\nprint_info: ssm_d_state      = 0\nprint_info: ssm_dt_rank      = 0\nprint_info: ssm_dt_b_c_rms   = 0\nprint_info: model type       = 7B\nprint_info: model params     = 6.74 B\nprint_info: general.name     = LLaMA v2\nprint_info: vocab type       = SPM\nprint_info: n_vocab          = 32001\nprint_info: n_merges         = 0\nprint_info: BOS token        = 1 '<s>'\nprint_info: EOS token        = 2 '</s>'\nprint_info: UNK token        = 0 '<unk>'\nprint_info: PAD token        = 32000 '<pad>'\nprint_info: LF token         = 13 '<0x0A>'\nprint_info: EOG token        = 2 '</s>'\nprint_info: max token length = 48\nload_tensors: layer   0 assigned to device CPU\nload_tensors: layer   1 assigned to device CPU\nload_tensors: layer   2 assigned to device CPU\nload_tensors: layer   3 assigned to device CPU\nload_tensors: layer   4 assigned to device CPU\nload_tensors: layer   5 assigned to device CPU\nload_tensors: layer   6 assigned to device CPU\nload_tensors: layer   7 assigned to device CPU\nload_tensors: layer   8 assigned to device CPU\nload_tensors: layer   9 assigned to device CPU\nload_tensors: layer  10 assigned to device CPU\nload_tensors: layer  11 assigned to device CPU\nload_tensors: layer  12 assigned to device CPU\nload_tensors: layer  13 assigned to device CPU\nload_tensors: layer  14 assigned to device CPU\nload_tensors: layer  15 assigned to device CPU\nload_tensors: layer  16 assigned to device CPU\nload_tensors: layer  17 assigned to device CPU\nload_tensors: layer  18 assigned to device CPU\nload_tensors: layer  19 assigned to device CPU\nload_tensors: layer  20 assigned to device CPU\nload_tensors: layer  21 assigned to device CPU\nload_tensors: layer  22 assigned to device CPU\nload_tensors: layer  23 assigned to device CPU\nload_tensors: layer  24 assigned to device CPU\nload_tensors: layer  25 assigned to device CPU\nload_tensors: layer  26 assigned to device CPU\nload_tensors: layer  27 assigned to device CPU\nload_tensors: layer  28 assigned to device CPU\nload_tensors: layer  29 assigned to device CPU\nload_tensors: layer  30 assigned to device CPU\nload_tensors: layer  31 assigned to device CPU\nload_tensors: layer  32 assigned to device CPU\nload_tensors: tensor 'token_embd.weight' (q5_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\nload_tensors:   CPU_Mapped model buffer size =  4560.87 MiB\nllama_init_from_model: n_seq_max     = 1\nllama_init_from_model: n_ctx         = 4096\nllama_init_from_model: n_ctx_per_seq = 4096\nllama_init_from_model: n_batch       = 512\nllama_init_from_model: n_ubatch      = 512\nllama_init_from_model: flash_attn    = 0\nllama_init_from_model: freq_base     = 10000.0\nllama_init_from_model: freq_scale    = 1\nllama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\nllama_kv_cache_init: layer 0: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 1: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 2: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 3: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 4: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 5: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 6: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 7: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 8: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 9: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 10: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 11: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 12: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 13: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 14: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 15: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 16: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 17: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 18: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 19: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 20: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 21: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 22: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 23: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 24: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 25: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 26: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 27: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 28: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 29: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 30: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init: layer 31: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\nllama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\nllama_init_from_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\nllama_init_from_model:        CPU  output buffer size =     0.12 MiB\nllama_init_from_model:        CPU compute buffer size =   296.01 MiB\nllama_init_from_model: graph nodes  = 1030\nllama_init_from_model: graph splits = 1\nCPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \nModel metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '32000', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '17'}\nUsing fallback chat format: llama-2\nllama_perf_context_print:        load time =   46002.60 ms\nllama_perf_context_print: prompt eval time =   46002.26 ms /   218 tokens (  211.02 ms per token,     4.74 tokens per second)\nllama_perf_context_print:        eval time =  164119.80 ms /   525 runs   (  312.61 ms per token,     3.20 tokens per second)\nllama_perf_context_print:       total time =  210683.81 ms /   743 tokens\n","output_type":"stream"},{"name":"stdout","text":"\nChatbot Response:\n--------------------------------------------------\n[/INST] Based on the user's request for sustainable finance strategies and sustainable stocks, I will provide a detailed analysis of the three stocks mentioned, ABBV, HD, and FMX, and recommend sustainable investing strategies.\n\nFirstly, I will analyze the ESG scores of the three stocks. ABBV has an ESG score of 26.0, with the lowest score being 1.0. HD has an ESG score of 12.6, and FMX has no ESG data available. Based on these scores, ABBV and HD have better ESG scores than FMX.\n\nNext, I will recommend sustainable investing strategies for ABBV, HD, and FMX. For ABBV, I recommend investing in renewable energy stocks, such as TAN, FAN, and DCP. For HD, I recommend investing in sustainable packaging companies, such as MPC, CPK and KDP. For FMX, I recommend investing in sustainable water companies, such as AWK and CWT.\n\nIn addition to investing in sustainable stocks, investors can also consider investing in environmental, social, and governance (ESG) funds. These funds invest in companies that have strong ESG practices and are committed to sustainability. Some popular ESG funds include Vanguard FTSE Social Index Fund, iShares ESG Aware MSCI USA ETF, and Invesco Global Clean Energy ETF.\n\nFinally, I will provide some insights on sustainable finance. Sustainable finance is an emerging field that seeks to align financial investments with sustainable development goals. It involves investing in companies that have strong ESG practices and are committed to sustainability. Sustainable finance is important because it can help mitigate the risks associated with climate change, such as rising sea levels, more frequent natural disasters, and water scarcity. It can also help companies achieve sustainable growth and long-term profitability.\n\nIn conclusion, sustainable finance is an important strategy for investors who want to align their investments with their values and support sustainable development. By investing in sustainable stocks and funds, investors can help create a more sustainable future for all.\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}